# Sound recognition review

Sound as data has been at the centre of attention of many scientists and engineers for decades. Sounds made by humans can be used for voice recognition (for example in security identifiers) or speech recognition (in human-computer interactions).  Non-human sounds can be of animal or mechanical origin. We can use this data for monitoring animal activity and population (birds or whales) or for detecting operating machinery and vehicles. The main difference between speech recognition and all other types of sound is nature of the task. We use only frequency patterns if we want to identify a bird by its song. For human speech recognition, we need to connect these frequencies to semantic meanings.

Any sounds recognition process can be divided into few steps:

* record a sample

* transform the sample into a spectrogram 

* divide the spectrogram into segments

* analyse the segment frequencies as features

* learn from the features

_(more detail to be added)_

Birds sound recognition review can be found [here](https://github.com/annavlz/distributed-learning/blob/master/reports/birds-sound-recognition.md).